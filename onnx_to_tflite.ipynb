{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "onnx_to_tflite.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-O5nMXxl3M-",
        "outputId": "6d523957-3798-47f5-d64f-90edc7811aad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"\"\"\n",
        "Authors\n",
        " * Tulasi Ram\n",
        "\"\"\"\n",
        "\n",
        "!pip install onnx\n",
        "!pip install git+https://github.com/onnx/onnx-tensorflow.git\n",
        "\n",
        "import onnx\n",
        "\n",
        "import tensorflow as tf\n",
        "from onnx_tf.backend import prepare"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.6/dist-packages (1.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from onnx) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.6/dist-packages (from onnx) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from onnx) (1.15.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from onnx) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->onnx) (50.3.2)\n",
            "Collecting git+https://github.com/onnx/onnx-tensorflow.git\n",
            "  Cloning https://github.com/onnx/onnx-tensorflow.git to /tmp/pip-req-build-ybjfd_tj\n",
            "  Running command git clone -q https://github.com/onnx/onnx-tensorflow.git /tmp/pip-req-build-ybjfd_tj\n",
            "Requirement already satisfied (use --upgrade to upgrade): onnx-tf==1.6.0 from git+https://github.com/onnx/onnx-tensorflow.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: onnx>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from onnx-tf==1.6.0) (1.8.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from onnx-tf==1.6.0) (3.13)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.6/dist-packages (from onnx>=1.6.0->onnx-tf==1.6.0) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from onnx>=1.6.0->onnx-tf==1.6.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from onnx>=1.6.0->onnx-tf==1.6.0) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from onnx>=1.6.0->onnx-tf==1.6.0) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->onnx>=1.6.0->onnx-tf==1.6.0) (50.3.2)\n",
            "Building wheels for collected packages: onnx-tf\n",
            "  Building wheel for onnx-tf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for onnx-tf: filename=onnx_tf-1.6.0-cp36-none-any.whl size=204404 sha256=ca9f27b54c387490d7c992bbb3962114c0a2f00e2a4bd3e826c2bafd9364bf8b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zsw0txvh/wheels/54/24/31/8873b33d2d560efdfa1ed6f346df67ef793b1897358705a480\n",
            "Successfully built onnx-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOZbTzEel9Qs",
        "outputId": "66d407e7-bca6-4d3a-8a93-4b35504dcc54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Export model to tensorflow\n",
        "\n",
        "# craft.onnx will be available after running this pytorch_to_onnx.ipynb\n",
        "\n",
        "onnx_model = onnx.load('craft.onnx')\n",
        "tf_rep = prepare(onnx_model)\n",
        "tf_rep.export_graph('craft.pb')\n",
        "\n",
        "print(\"Model converted to tensorflow graph succesfully.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: craft.pb/assets\n",
            "Model converted to tensorflow graph succesfully.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73ePeQJgmA5z",
        "outputId": "2aa86e06-5d07-46fe-c61c-34979e842139",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "loaded = tf.saved_model.load('craft.pb')\n",
        "\n",
        "concrete_func = loaded.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
        "\n",
        "concrete_func.inputs[0].set_shape([None, 3, 1280, 800])\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "tf_lite_model = converter.convert()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Using experimental converter: If you encountered a problem please file a bug. You can opt-out by setting experimental_new_converter=False\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf6XxRmxm1zi",
        "outputId": "e9ff0b4d-e004-4b05-9a7b-07ca34ce806b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "open('craft.tflite', 'wb').write(tf_lite_model)\n",
        "\n",
        "print(\"Converted to tensorflow lite succesfully.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted to tensorflow lite succesfully.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzBGjrVUp7VF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}