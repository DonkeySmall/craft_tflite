{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "savedmodel_to_tflite.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BqviuI5h5pB"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tulasiram58827/craft_tflite/blob/main/colabs/savedmodel_to_tflite.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHY8tTMXiAI0"
      },
      "source": [
        "This notebook converts tensorflow savel model to tflite version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKGw8JrOiANr"
      },
      "source": [
        "## SetUp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKvC5It8iGVZ"
      },
      "source": [
        "\"\"\"\n",
        "Authors\n",
        " * Tulasi Ram\n",
        "\"\"\"\n",
        "!pip install tf-nightly\n",
        "!pip install onnx\n",
        "!pip install git+https://github.com/onnx/onnx-tensorflow.git\n",
        "\n",
        "import onnx\n",
        "\n",
        "import tensorflow as tf\n",
        "from onnx_tf.backend import prepare"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPBqd567iPKl"
      },
      "source": [
        "### Export to Tensorflow Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3MRByisiJ25"
      },
      "source": [
        "# Export model to tensorflow\n",
        "\n",
        "!wget https://github.com/tulasiram58827/craft_tflite/blob/main/models/craft.onnx?raw=true -O craft.onnx\n",
        "onnx_model = onnx.load('/content/craft.onnx')\n",
        "\n",
        "tf_rep = prepare(onnx_model)\n",
        "tf_rep.export_graph('craft.pb')\n",
        "\n",
        "print(\"Model converted to tensorflow graph succesfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0SPMvmgjMNW",
        "outputId": "30707160-fdd4-4bf9-fdf3-c5c82a952ab0"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1HvujMMNCG49esPpZOHEnPFY6k-khbrmZ\n",
        "!unzip /content/image_files.zip\n",
        "dataset_path = '/content/image_files/'\n",
        "\n",
        "\n",
        "loaded = tf.saved_model.load('/content/craft.pb')\n",
        "\n",
        "concrete_func = loaded.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
        "\n",
        "concrete_func.inputs[0].set_shape([None, 3, 320, 200])\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HvujMMNCG49esPpZOHEnPFY6k-khbrmZ\n",
            "To: /content/image_files.zip\n",
            "\r0.00B [00:00, ?B/s]\r7.30MB [00:00, 64.1MB/s]\n",
            "Archive:  /content/image_files.zip\n",
            "replace image_files/000.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: image_files/000.jpg     \n",
            "  inflating: image_files/001.jpg     \n",
            "  inflating: image_files/002.jpg     \n",
            "  inflating: image_files/003.jpg     \n",
            "  inflating: image_files/004.jpg     \n",
            "  inflating: image_files/005.jpg     \n",
            "  inflating: image_files/006.jpg     \n",
            "  inflating: image_files/007.jpg     \n",
            "  inflating: image_files/008.jpg     \n",
            "  inflating: image_files/009.jpg     \n",
            "  inflating: image_files/010.jpg     \n",
            "  inflating: image_files/011.jpg     \n",
            "  inflating: image_files/012.jpg     \n",
            "  inflating: image_files/013.jpg     \n",
            "  inflating: image_files/014.jpg     \n",
            "  inflating: image_files/015.jpg     \n",
            "  inflating: image_files/016.jpg     \n",
            "  inflating: image_files/017.jpg     \n",
            "  inflating: image_files/018.jpg     \n",
            "  inflating: image_files/019.jpg     \n",
            "  inflating: image_files/020.jpg     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yDk70RLhlqWT",
        "outputId": "d464f59d-9dfd-4e32-e78b-1bed18c1acc9"
      },
      "source": [
        "# Uncomment this line for float16 quantization.\n",
        "# converter.target_spec.supported_types = [tf.float16]\n",
        "# converter.target_spec.supported_types = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
        "\n",
        "\n",
        "# Uncomment For Integer Quantization\n",
        "# def representative_data_gen():\n",
        "#     for file in os.listdir(dataset_path)[:10]:\n",
        "#         file_path = dataset_path+file\n",
        "#         image = imgproc.loadImage(file_path)\n",
        "#         image = cv2.resize(image, dsize=(800, 1280), interpolation=cv2.INTER_LINEAR)\n",
        "#         img_resized, target_ratio, size_heatmap = imgproc.resize_aspect_ratio(image, 1280, interpolation=cv2.INTER_LINEAR, mag_ratio=1.5)\n",
        "#         ratio_h = ratio_w = 1 / target_ratio\n",
        "\n",
        "#         # preprocessing\n",
        "#         x = imgproc.normalizeMeanVariance(img_resized)\n",
        "#         x = torch.from_numpy(x).permute(2, 0, 1)    # [h, w, c] to [c, h, w]\n",
        "#         x = Variable(x.unsqueeze(0))                # [c, h, w] to [b, c, h, w]\n",
        "#         x = x.cpu().detach().numpy()\n",
        "#         yield [x]\n",
        "\n",
        "# converter.representative_dataset = representative_data_gen\n",
        "\n",
        "tf_lite_model = converter.convert()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Using new converter: If you encounter a problem please file a bug. You can opt-out by setting experimental_new_converter=False\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ConverterError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    212\u001b[0m                                                  \u001b[0mdebug_info_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                                                  enable_mlir_converter)\n\u001b[0m\u001b[1;32m    214\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/wrap_toco.py\u001b[0m in \u001b[0;36mwrapped_toco_convert\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0mdebug_info_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m       enable_mlir_converter)\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:891:0: error: 'tf.MaxPool' op is neither a custom op nor a flex op\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:860:0: note: called from\n<ipython-input-14-043a35de6c70>:6:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:233:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:891:0: error: 'tf.MaxPool' op is neither a custom op nor a flex op\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:860:0: note: called from\n<ipython-input-14-043a35de6c70>:6:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:233:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:891:0: error: 'tf.MaxPool' op is neither a custom op nor a flex op\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:860:0: note: called from\n<ipython-input-14-043a35de6c70>:6:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:233:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:891:0: error: 'tf.MaxPool' op is neither a custom op nor a flex op\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:860:0: note: called from\n<ipython-input-14-043a35de6c70>:6:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:233:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:891:0: error: 'tf.MaxPool' op is neither a custom op nor a flex op\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:860:0: note: called from\n<ipython-input-14-043a35de6c70>:6:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:233:0: note: called from\n<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\n\ttf.MaxPool {data_format = \"NCHW\", device = \"\", explicit_paddings = [], ksize = [1, 1, 2, 2], padding = \"VALID\", strides = [1, 1, 2, 2]}\n\ttf.MaxPool {data_format = \"NCHW\", device = \"\", explicit_paddings = [], ksize = [1, 1, 3, 3], padding = \"VALID\", strides = [1, 1, 1, 1]}\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-db34eaeeef14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# converter.representative_dataset = representative_data_gen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtf_lite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0mInvalid\u001b[0m \u001b[0mquantization\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \"\"\"\n\u001b[0;32m-> 1124\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTFLiteConverterV2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     return super(TFLiteFrozenGraphConverterV2,\n\u001b[0;32m--> 950\u001b[0;31m                  self).convert(graph_def, input_tensors, output_tensors)\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0moutput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m         **converter_kwargs)\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[0mcalibrate_and_quantize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquant_mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantizer_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_impl\u001b[0;34m(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0mdebug_info_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug_info_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m       enable_mlir_converter=enable_mlir_converter)\n\u001b[0m\u001b[1;32m    615\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    214\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mConverterError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_executable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_toco_from_proto_bin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConverterError\u001b[0m: /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:891:0: error: 'tf.MaxPool' op is neither a custom op nor a flex op\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:860:0: note: called from\n<ipython-input-14-043a35de6c70>:6:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:233:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:891:0: error: 'tf.MaxPool' op is neither a custom op nor a flex op\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:860:0: note: called from\n<ipython-input-14-043a35de6c70>:6:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:233:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:891:0: error: 'tf.MaxPool' op is neither a custom op nor a flex op\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:860:0: note: called from\n<ipython-input-14-043a35de6c70>:6:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:233:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:891:0: error: 'tf.MaxPool' op is neither a custom op nor a flex op\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:860:0: note: called from\n<ipython-input-14-043a35de6c70>:6:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:233:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:891:0: error: 'tf.MaxPool' op is neither a custom op nor a flex op\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:860:0: note: called from\n<ipython-input-14-043a35de6c70>:6:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:233:0: note: called from\n<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\n\ttf.MaxPool {data_format = \"NCHW\", device = \"\", explicit_paddings = [], ksize = [1, 1, 2, 2], padding = \"VALID\", strides = [1, 1, 2, 2]}\n\ttf.MaxPool {data_format = \"NCHW\", device = \"\", explicit_paddings = [], ksize = [1, 1, 3, 3], padding = \"VALID\", strides = [1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b0Sn3NUm6hh"
      },
      "source": [
        "open('craft.tflite', 'wb').write(tf_lite_model)\n",
        "\n",
        "print(\"Converted to tensorflow lite succesfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}