{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BqviuI5h5pB"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tulasiram58827/craft_tflite/blob/main/colabs/savedmodel_to_tflite.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHY8tTMXiAI0"
   },
   "source": [
    "This notebook converts tensorflow savel model to tflite version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKGw8JrOiANr"
   },
   "source": [
    "## SetUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fKvC5It8iGVZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in /home/ram/anaconda3/lib/python3.8/site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy in /home/ram/anaconda3/lib/python3.8/site-packages (from onnx) (1.18.5)\n",
      "Requirement already satisfied: protobuf in /home/ram/anaconda3/lib/python3.8/site-packages (from onnx) (3.13.0)\n",
      "Requirement already satisfied: six in /home/ram/anaconda3/lib/python3.8/site-packages (from onnx) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /home/ram/anaconda3/lib/python3.8/site-packages (from onnx) (3.7.4.2)\n",
      "Requirement already satisfied: setuptools in /home/ram/anaconda3/lib/python3.8/site-packages (from protobuf->onnx) (49.2.0.post20200714)\n",
      "Collecting git+https://github.com/onnx/onnx-tensorflow.git\n",
      "  Cloning https://github.com/onnx/onnx-tensorflow.git to /tmp/pip-req-build-n056aohb\n",
      "Requirement already satisfied (use --upgrade to upgrade): onnx-tf==1.6.0 from git+https://github.com/onnx/onnx-tensorflow.git in /home/ram/anaconda3/lib/python3.8/site-packages\n",
      "Requirement already satisfied: onnx>=1.6.0 in /home/ram/anaconda3/lib/python3.8/site-packages (from onnx-tf==1.6.0) (1.8.0)\n",
      "Requirement already satisfied: PyYAML in /home/ram/anaconda3/lib/python3.8/site-packages (from onnx-tf==1.6.0) (5.3.1)\n",
      "Requirement already satisfied: numpy in /home/ram/anaconda3/lib/python3.8/site-packages (from onnx>=1.6.0->onnx-tf==1.6.0) (1.18.5)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /home/ram/anaconda3/lib/python3.8/site-packages (from onnx>=1.6.0->onnx-tf==1.6.0) (3.7.4.2)\n",
      "Requirement already satisfied: protobuf in /home/ram/anaconda3/lib/python3.8/site-packages (from onnx>=1.6.0->onnx-tf==1.6.0) (3.13.0)\n",
      "Requirement already satisfied: six in /home/ram/anaconda3/lib/python3.8/site-packages (from onnx>=1.6.0->onnx-tf==1.6.0) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /home/ram/anaconda3/lib/python3.8/site-packages (from protobuf->onnx>=1.6.0->onnx-tf==1.6.0) (49.2.0.post20200714)\n",
      "Building wheels for collected packages: onnx-tf\n",
      "  Building wheel for onnx-tf (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for onnx-tf: filename=onnx_tf-1.6.0-py3-none-any.whl size=205527 sha256=8925f7dede35c9245de1b93654b29be9b8f5b55595ba25657c1eea7c9abecd10\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-r75384fn/wheels/e9/b7/67/8abcf50ca14ef4375302d30abf9f4242e06be09b829f5fd307\n",
      "Successfully built onnx-tf\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Authors\n",
    " * Tulasi Ram\n",
    "\"\"\"\n",
    "!pip install onnx\n",
    "!pip install git+https://github.com/onnx/onnx-tensorflow.git\n",
    "\n",
    "import onnx\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from skimage import io\n",
    "import tensorflow as tf\n",
    "from onnx_tf.backend import prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImage(img_file):\n",
    "    img = io.imread(img_file)           # RGB order\n",
    "    if img.shape[0] == 2: img = img[0]\n",
    "    if len(img.shape) == 2 : img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    if img.shape[2] == 4:   img = img[:,:,:3]\n",
    "    img = np.array(img)\n",
    "\n",
    "    return img\n",
    "\n",
    "def normalizeMeanVariance(in_img, mean=(0.485, 0.456, 0.406), variance=(0.229, 0.224, 0.225)):\n",
    "    # should be RGB order\n",
    "    img = in_img.copy().astype(np.float32)\n",
    "\n",
    "    img -= np.array([mean[0] * 255.0, mean[1] * 255.0, mean[2] * 255.0], dtype=np.float32)\n",
    "    img /= np.array([variance[0] * 255.0, variance[1] * 255.0, variance[2] * 255.0], dtype=np.float32)\n",
    "    return img\n",
    "\n",
    "def denormalizeMeanVariance(in_img, mean=(0.485, 0.456, 0.406), variance=(0.229, 0.224, 0.225)):\n",
    "    # should be RGB order\n",
    "    img = in_img.copy()\n",
    "    img *= variance\n",
    "    img += mean\n",
    "    img *= 255.0\n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def resize_aspect_ratio(img, square_size, interpolation, mag_ratio=1):\n",
    "    height, width, channel = img.shape\n",
    "\n",
    "    # magnify image size\n",
    "    target_size = mag_ratio * max(height, width)\n",
    "\n",
    "    # set original image size\n",
    "    if target_size > square_size:\n",
    "        target_size = square_size\n",
    "    \n",
    "    ratio = target_size / max(height, width)    \n",
    "\n",
    "    target_h, target_w = int(height * ratio), int(width * ratio)\n",
    "    proc = cv2.resize(img, (target_w, target_h), interpolation = interpolation)\n",
    "\n",
    "\n",
    "    # make canvas and paste image\n",
    "    target_h32, target_w32 = target_h, target_w\n",
    "    if target_h % 32 != 0:\n",
    "        target_h32 = target_h + (32 - target_h % 32)\n",
    "    if target_w % 32 != 0:\n",
    "        target_w32 = target_w + (32 - target_w % 32)\n",
    "    resized = np.zeros((target_h32, target_w32, channel), dtype=np.float32)\n",
    "    resized[0:target_h, 0:target_w, :] = proc\n",
    "    target_h, target_w = target_h32, target_w32\n",
    "\n",
    "    size_heatmap = (int(target_w/2), int(target_h/2))\n",
    "\n",
    "    return resized, ratio, size_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveResult(img_file, img, boxes, dirname='./result/', verticals=None, texts=None):\n",
    "        \"\"\" save text detection result one by one\n",
    "        Args:\n",
    "            img_file (str): image file name\n",
    "            img (array): raw image context\n",
    "            boxes (array): array of result file\n",
    "                Shape: [num_detections, 4] for BB output / [num_detections, 4] for QUAD output\n",
    "        Return:\n",
    "            None\n",
    "        \"\"\"\n",
    "        img = np.array(img)\n",
    "\n",
    "        # make result file list\n",
    "        filename, file_ext = os.path.splitext(os.path.basename(img_file))\n",
    "\n",
    "        # result directory\n",
    "        res_file = dirname + \"res_\" + filename + '.txt'\n",
    "        res_img_file = dirname + \"res_\" + filename + '.jpg'\n",
    "\n",
    "        if not os.path.isdir(dirname):\n",
    "            os.mkdir(dirname)\n",
    "        #data = open('task3.txt', 'w')\n",
    "        count = 0\n",
    "        with open(res_file, 'w') as f:\n",
    "            for i, box in enumerate(boxes):\n",
    "                #text = save_polygon(img, box, count)\n",
    "                #box_data = \"\"\n",
    "                #for co_ord in box:\n",
    "                #    box_data+=f\"{co_ord[0]}, {co_ord[1]}\"\n",
    "                #print(box_data, text)\n",
    "                #data.write(box_data+\",\"+text+\"\\n\")\n",
    "                #count+=1\n",
    "                poly = np.array(box).astype(np.int32).reshape((-1))\n",
    "                #strResult = ','.join([str(p) for p in poly]) + '\\r\\n'\n",
    "                #f.write(strResult)\n",
    "                poly = poly.reshape(-1, 2)\n",
    "                min_co = tuple(np.min(poly, axis=0))\n",
    "                max_co = tuple(np.max(poly, axis=0))\n",
    "                #x_1, x_2, y_1, y_2 = poly[0][0], poly[1][0], poly[1][1], poly[2][1]\n",
    "                cv2.rectangle(img, min_co, max_co, (0, 0, 255), 2)\n",
    "                #cv2.polylines(img, [poly.reshape((-1, 1, 2))], True, color=(0, 0, 255), thickness=2)\n",
    "                ptColor = (0, 255, 255)\n",
    "                if verticals is not None:\n",
    "                    if verticals[i]:\n",
    "                        ptColor = (255, 0, 0)\n",
    "\n",
    "                if texts is not None:\n",
    "                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    font_scale = 0.5\n",
    "                    cv2.putText(img, \"{}\".format(texts[i]), (poly[0][0]+1, poly[0][1]+1), font, font_scale, (0, 0, 0), thickness=1)\n",
    "                    cv2.putText(img, \"{}\".format(texts[i]), tuple(poly[0]), font, font_scale, (0, 255, 255), thickness=1)\n",
    "\n",
    "        # Save result image\n",
    "        cv2.imwrite(res_img_file, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" auxilary functions \"\"\"\n",
    "# unwarp corodinates\n",
    "def warpCoord(Minv, pt):\n",
    "    out = np.matmul(Minv, (pt[0], pt[1], 1))\n",
    "    return np.array([out[0]/out[2], out[1]/out[2]])\n",
    "\"\"\" end of auxilary functions \"\"\"\n",
    "\n",
    "\n",
    "def getDetBoxes_core(textmap, linkmap, text_threshold, link_threshold, low_text):\n",
    "    # prepare data\n",
    "    linkmap = linkmap.copy()\n",
    "    textmap = textmap.copy()\n",
    "    img_h, img_w = textmap.shape\n",
    "\n",
    "    \"\"\" labeling method \"\"\"\n",
    "    ret, text_score = cv2.threshold(textmap, low_text, 1, 0)\n",
    "    ret, link_score = cv2.threshold(linkmap, link_threshold, 1, 0)\n",
    "\n",
    "    text_score_comb = np.clip(text_score + link_score, 0, 1)\n",
    "    nLabels, labels, stats, centroids = cv2.connectedComponentsWithStats(text_score_comb.astype(np.uint8), connectivity=4)\n",
    "\n",
    "    det = []\n",
    "    mapper = []\n",
    "    for k in range(1,nLabels):\n",
    "        # size filtering\n",
    "        size = stats[k, cv2.CC_STAT_AREA]\n",
    "        if size < 10: continue\n",
    "\n",
    "        # thresholding\n",
    "        if np.max(textmap[labels==k]) < text_threshold: continue\n",
    "\n",
    "        # make segmentation map\n",
    "        segmap = np.zeros(textmap.shape, dtype=np.uint8)\n",
    "        segmap[labels==k] = 255\n",
    "        segmap[np.logical_and(link_score==1, text_score==0)] = 0   # remove link area\n",
    "        x, y = stats[k, cv2.CC_STAT_LEFT], stats[k, cv2.CC_STAT_TOP]\n",
    "        w, h = stats[k, cv2.CC_STAT_WIDTH], stats[k, cv2.CC_STAT_HEIGHT]\n",
    "        niter = int(math.sqrt(size * min(w, h) / (w * h)) * 2)\n",
    "        sx, ex, sy, ey = x - niter, x + w + niter + 1, y - niter, y + h + niter + 1\n",
    "        # boundary check\n",
    "        if sx < 0 : sx = 0\n",
    "        if sy < 0 : sy = 0\n",
    "        if ex >= img_w: ex = img_w\n",
    "        if ey >= img_h: ey = img_h\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(1 + niter, 1 + niter))\n",
    "        segmap[sy:ey, sx:ex] = cv2.dilate(segmap[sy:ey, sx:ex], kernel)\n",
    "\n",
    "        # make box\n",
    "        np_contours = np.roll(np.array(np.where(segmap!=0)),1,axis=0).transpose().reshape(-1,2)\n",
    "        rectangle = cv2.minAreaRect(np_contours)\n",
    "        box = cv2.boxPoints(rectangle)\n",
    "\n",
    "        # align diamond-shape\n",
    "        w, h = np.linalg.norm(box[0] - box[1]), np.linalg.norm(box[1] - box[2])\n",
    "        box_ratio = max(w, h) / (min(w, h) + 1e-5)\n",
    "        if abs(1 - box_ratio) <= 0.1:\n",
    "            l, r = min(np_contours[:,0]), max(np_contours[:,0])\n",
    "            t, b = min(np_contours[:,1]), max(np_contours[:,1])\n",
    "            box = np.array([[l, t], [r, t], [r, b], [l, b]], dtype=np.float32)\n",
    "\n",
    "        # make clock-wise order\n",
    "        startidx = box.sum(axis=1).argmin()\n",
    "        box = np.roll(box, 4-startidx, 0)\n",
    "        box = np.array(box)\n",
    "\n",
    "        det.append(box)\n",
    "        mapper.append(k)\n",
    "\n",
    "    return det, labels, mapper\n",
    "\n",
    "def getPoly_core(boxes, labels, mapper, linkmap):\n",
    "    # configs\n",
    "    num_cp = 5\n",
    "    max_len_ratio = 0.7\n",
    "    expand_ratio = 1.45\n",
    "    max_r = 2.0\n",
    "    step_r = 0.2\n",
    "\n",
    "    polys = []  \n",
    "    for k, box in enumerate(boxes):\n",
    "        # size filter for small instance\n",
    "        w, h = int(np.linalg.norm(box[0] - box[1]) + 1), int(np.linalg.norm(box[1] - box[2]) + 1)\n",
    "        if w < 10 or h < 10:\n",
    "            polys.append(None); continue\n",
    "\n",
    "        # warp image\n",
    "        tar = np.float32([[0,0],[w,0],[w,h],[0,h]])\n",
    "        M = cv2.getPerspectiveTransform(box, tar)\n",
    "        word_label = cv2.warpPerspective(labels, M, (w, h), flags=cv2.INTER_NEAREST)\n",
    "        try:\n",
    "            Minv = np.linalg.inv(M)\n",
    "        except:\n",
    "            polys.append(None); continue\n",
    "\n",
    "        # binarization for selected label\n",
    "        cur_label = mapper[k]\n",
    "        word_label[word_label != cur_label] = 0\n",
    "        word_label[word_label > 0] = 1\n",
    "\n",
    "        \"\"\" Polygon generation \"\"\"\n",
    "        # find top/bottom contours\n",
    "        cp = []\n",
    "        max_len = -1\n",
    "        for i in range(w):\n",
    "            region = np.where(word_label[:,i] != 0)[0]\n",
    "            if len(region) < 2 : continue\n",
    "            cp.append((i, region[0], region[-1]))\n",
    "            length = region[-1] - region[0] + 1\n",
    "            if length > max_len: max_len = length\n",
    "\n",
    "        # pass if max_len is similar to h\n",
    "        if h * max_len_ratio < max_len:\n",
    "            polys.append(None); continue\n",
    "\n",
    "        # get pivot points with fixed length\n",
    "        tot_seg = num_cp * 2 + 1\n",
    "        seg_w = w / tot_seg     # segment width\n",
    "        pp = [None] * num_cp    # init pivot points\n",
    "        cp_section = [[0, 0]] * tot_seg\n",
    "        seg_height = [0] * num_cp\n",
    "        seg_num = 0\n",
    "        num_sec = 0\n",
    "        prev_h = -1\n",
    "        for i in range(0,len(cp)):\n",
    "            (x, sy, ey) = cp[i]\n",
    "            if (seg_num + 1) * seg_w <= x and seg_num <= tot_seg:\n",
    "                # average previous segment\n",
    "                if num_sec == 0: break\n",
    "                cp_section[seg_num] = [cp_section[seg_num][0] / num_sec, cp_section[seg_num][1] / num_sec]\n",
    "                num_sec = 0\n",
    "\n",
    "                # reset variables\n",
    "                seg_num += 1\n",
    "                prev_h = -1\n",
    "\n",
    "            # accumulate center points\n",
    "            cy = (sy + ey) * 0.5\n",
    "            cur_h = ey - sy + 1\n",
    "            cp_section[seg_num] = [cp_section[seg_num][0] + x, cp_section[seg_num][1] + cy]\n",
    "            num_sec += 1\n",
    "\n",
    "            if seg_num % 2 == 0: continue # No polygon area\n",
    "\n",
    "            if prev_h < cur_h:\n",
    "                pp[int((seg_num - 1)/2)] = (x, cy)\n",
    "                seg_height[int((seg_num - 1)/2)] = cur_h\n",
    "                prev_h = cur_h\n",
    "\n",
    "        # processing last segment\n",
    "        if num_sec != 0:\n",
    "            cp_section[-1] = [cp_section[-1][0] / num_sec, cp_section[-1][1] / num_sec]\n",
    "\n",
    "        # pass if num of pivots is not sufficient or segment widh is smaller than character height \n",
    "        if None in pp or seg_w < np.max(seg_height) * 0.25:\n",
    "            polys.append(None); continue\n",
    "\n",
    "        # calc median maximum of pivot points\n",
    "        half_char_h = np.median(seg_height) * expand_ratio / 2\n",
    "\n",
    "        # calc gradiant and apply to make horizontal pivots\n",
    "        new_pp = []\n",
    "        for i, (x, cy) in enumerate(pp):\n",
    "            dx = cp_section[i * 2 + 2][0] - cp_section[i * 2][0]\n",
    "            dy = cp_section[i * 2 + 2][1] - cp_section[i * 2][1]\n",
    "            if dx == 0:     # gradient if zero\n",
    "                new_pp.append([x, cy - half_char_h, x, cy + half_char_h])\n",
    "                continue\n",
    "            rad = - math.atan2(dy, dx)\n",
    "            c, s = half_char_h * math.cos(rad), half_char_h * math.sin(rad)\n",
    "            new_pp.append([x - s, cy - c, x + s, cy + c])\n",
    "\n",
    "        # get edge points to cover character heatmaps\n",
    "        isSppFound, isEppFound = False, False\n",
    "        grad_s = (pp[1][1] - pp[0][1]) / (pp[1][0] - pp[0][0]) + (pp[2][1] - pp[1][1]) / (pp[2][0] - pp[1][0])\n",
    "        grad_e = (pp[-2][1] - pp[-1][1]) / (pp[-2][0] - pp[-1][0]) + (pp[-3][1] - pp[-2][1]) / (pp[-3][0] - pp[-2][0])\n",
    "        for r in np.arange(0.5, max_r, step_r):\n",
    "            dx = 2 * half_char_h * r\n",
    "            if not isSppFound:\n",
    "                line_img = np.zeros(word_label.shape, dtype=np.uint8)\n",
    "                dy = grad_s * dx\n",
    "                p = np.array(new_pp[0]) - np.array([dx, dy, dx, dy])\n",
    "                cv2.line(line_img, (int(p[0]), int(p[1])), (int(p[2]), int(p[3])), 1, thickness=1)\n",
    "                if np.sum(np.logical_and(word_label, line_img)) == 0 or r + 2 * step_r >= max_r:\n",
    "                    spp = p\n",
    "                    isSppFound = True\n",
    "            if not isEppFound:\n",
    "                line_img = np.zeros(word_label.shape, dtype=np.uint8)\n",
    "                dy = grad_e * dx\n",
    "                p = np.array(new_pp[-1]) + np.array([dx, dy, dx, dy])\n",
    "                cv2.line(line_img, (int(p[0]), int(p[1])), (int(p[2]), int(p[3])), 1, thickness=1)\n",
    "                if np.sum(np.logical_and(word_label, line_img)) == 0 or r + 2 * step_r >= max_r:\n",
    "                    epp = p\n",
    "                    isEppFound = True\n",
    "            if isSppFound and isEppFound:\n",
    "                break\n",
    "\n",
    "        # pass if boundary of polygon is not found\n",
    "        if not (isSppFound and isEppFound):\n",
    "            polys.append(None); continue\n",
    "\n",
    "        # make final polygon\n",
    "        poly = []\n",
    "        poly.append(warpCoord(Minv, (spp[0], spp[1])))\n",
    "        for p in new_pp:\n",
    "            poly.append(warpCoord(Minv, (p[0], p[1])))\n",
    "        poly.append(warpCoord(Minv, (epp[0], epp[1])))\n",
    "        poly.append(warpCoord(Minv, (epp[2], epp[3])))\n",
    "        for p in reversed(new_pp):\n",
    "            poly.append(warpCoord(Minv, (p[2], p[3])))\n",
    "        poly.append(warpCoord(Minv, (spp[2], spp[3])))\n",
    "\n",
    "        # add to final result\n",
    "        polys.append(np.array(poly))\n",
    "\n",
    "    return polys\n",
    "\n",
    "def getDetBoxes(textmap, linkmap, text_threshold, link_threshold, low_text, poly=False):\n",
    "    boxes, labels, mapper = getDetBoxes_core(textmap, linkmap, text_threshold, link_threshold, low_text)\n",
    "\n",
    "    if poly:\n",
    "        polys = getPoly_core(boxes, labels, mapper, linkmap)\n",
    "    else:\n",
    "        polys = [None] * len(boxes)\n",
    "\n",
    "    return boxes, polys\n",
    "\n",
    "def adjustResultCoordinates(polys, ratio_w, ratio_h, ratio_net = 2):\n",
    "    if len(polys) > 0:\n",
    "        polys = np.array(polys)\n",
    "        for k in range(len(polys)):\n",
    "            if polys[k] is not None:\n",
    "                polys[k] *= (ratio_w * ratio_net, ratio_h * ratio_net)\n",
    "    return polys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPBqd567iPKl"
   },
   "source": [
    "### Export to Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3MRByisiJ25"
   },
   "outputs": [],
   "source": [
    "# Export model to tensorflow\n",
    "\n",
    "!wget https://github.com/tulasiram58827/craft_tflite/blob/main/models/craft.onnx?raw=true -O craft.onnx\n",
    "onnx_model = onnx.load('/content/craft.onnx')\n",
    "\n",
    "tf_rep = prepare(onnx_model)\n",
    "tf_rep.export_graph('craft.pb')\n",
    "\n",
    "print(\"Model converted to tensorflow graph succesfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H0SPMvmgjMNW",
    "outputId": "30707160-fdd4-4bf9-fdf3-c5c82a952ab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1HvujMMNCG49esPpZOHEnPFY6k-khbrmZ\n",
      "To: /content/image_files.zip\n",
      "\r",
      "0.00B [00:00, ?B/s]\r",
      "7.30MB [00:00, 64.1MB/s]\n",
      "Archive:  /content/image_files.zip\n",
      "replace image_files/000.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
      "  inflating: image_files/000.jpg     \n",
      "  inflating: image_files/001.jpg     \n",
      "  inflating: image_files/002.jpg     \n",
      "  inflating: image_files/003.jpg     \n",
      "  inflating: image_files/004.jpg     \n",
      "  inflating: image_files/005.jpg     \n",
      "  inflating: image_files/006.jpg     \n",
      "  inflating: image_files/007.jpg     \n",
      "  inflating: image_files/008.jpg     \n",
      "  inflating: image_files/009.jpg     \n",
      "  inflating: image_files/010.jpg     \n",
      "  inflating: image_files/011.jpg     \n",
      "  inflating: image_files/012.jpg     \n",
      "  inflating: image_files/013.jpg     \n",
      "  inflating: image_files/014.jpg     \n",
      "  inflating: image_files/015.jpg     \n",
      "  inflating: image_files/016.jpg     \n",
      "  inflating: image_files/017.jpg     \n",
      "  inflating: image_files/018.jpg     \n",
      "  inflating: image_files/019.jpg     \n",
      "  inflating: image_files/020.jpg     \n"
     ]
    }
   ],
   "source": [
    "!gdown https://drive.google.com/uc?id=1HvujMMNCG49esPpZOHEnPFY6k-khbrmZ\n",
    "!unzip /content/image_files.zip\n",
    "dataset_path = '/content/image_files/'\n",
    "\n",
    "\n",
    "loaded = tf.saved_model.load('/content/craft.pb')\n",
    "\n",
    "concrete_func = loaded.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "\n",
    "concrete_func.inputs[0].set_shape([None, 3, 800, 600])\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yDk70RLhlqWT",
    "outputId": "d464f59d-9dfd-4e32-e78b-1bed18c1acc9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using new converter: If you encounter a problem please file a bug. You can opt-out by setting experimental_new_converter=False\n"
     ]
    },
    {
     "ename": "ConverterError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    212\u001b[0m                                                  \u001b[0mdebug_info_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                                                  enable_mlir_converter)\n\u001b[0m\u001b[1;32m    214\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/wrap_toco.py\u001b[0m in \u001b[0;36mwrapped_toco_convert\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0mdebug_info_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m       enable_mlir_converter)\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:891:0: error: 'tf.MaxPool' op is neither a custom op nor a flex op\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:860:0: note: called from\n<ipython-input-14-043a35de6c70>:6:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:233:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:891:0: error: 'tf.MaxPool' op is neither a custom op nor a flex op\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:860:0: note: called from\n<ipython-input-14-043a35de6c70>:6:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:233:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:891:0: error: 'tf.MaxPool' op is neither a custom op nor a flex op\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:860:0: note: called from\n<ipython-input-14-043a35de6c70>:6:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:233:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:891:0: error: 'tf.MaxPool' op is neither a custom op nor a flex op\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:860:0: note: called from\n<ipython-input-14-043a35de6c70>:6:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:233:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:891:0: error: 'tf.MaxPool' op is neither a custom op nor a flex op\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:860:0: note: called from\n<ipython-input-14-043a35de6c70>:6:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:233:0: note: called from\n<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\n\ttf.MaxPool {data_format = \"NCHW\", device = \"\", explicit_paddings = [], ksize = [1, 1, 2, 2], padding = \"VALID\", strides = [1, 1, 2, 2]}\n\ttf.MaxPool {data_format = \"NCHW\", device = \"\", explicit_paddings = [], ksize = [1, 1, 3, 3], padding = \"VALID\", strides = [1, 1, 1, 1]}\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-db34eaeeef14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# converter.representative_dataset = representative_data_gen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtf_lite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0mInvalid\u001b[0m \u001b[0mquantization\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \"\"\"\n\u001b[0;32m-> 1124\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTFLiteConverterV2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     return super(TFLiteFrozenGraphConverterV2,\n\u001b[0;32m--> 950\u001b[0;31m                  self).convert(graph_def, input_tensors, output_tensors)\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0moutput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m         **converter_kwargs)\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[0mcalibrate_and_quantize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquant_mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantizer_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_impl\u001b[0;34m(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0mdebug_info_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug_info_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m       enable_mlir_converter=enable_mlir_converter)\n\u001b[0m\u001b[1;32m    615\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    214\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mConverterError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_executable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_toco_from_proto_bin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConverterError\u001b[0m: /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:891:0: error: 'tf.MaxPool' op is neither a custom op nor a flex op\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:860:0: note: called from\n<ipython-input-14-043a35de6c70>:6:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:233:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:891:0: error: 'tf.MaxPool' op is neither a custom op nor a flex op\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:860:0: note: called from\n<ipython-input-14-043a35de6c70>:6:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:233:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:891:0: error: 'tf.MaxPool' op is neither a custom op nor a flex op\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:860:0: note: called from\n<ipython-input-14-043a35de6c70>:6:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:233:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:891:0: error: 'tf.MaxPool' op is neither a custom op nor a flex op\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:860:0: note: called from\n<ipython-input-14-043a35de6c70>:6:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:233:0: note: called from\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:891:0: error: 'tf.MaxPool' op is neither a custom op nor a flex op\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:860:0: note: called from\n<ipython-input-14-043a35de6c70>:6:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:0: note: called from\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:233:0: note: called from\n<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\n\ttf.MaxPool {data_format = \"NCHW\", device = \"\", explicit_paddings = [], ksize = [1, 1, 2, 2], padding = \"VALID\", strides = [1, 1, 2, 2]}\n\ttf.MaxPool {data_format = \"NCHW\", device = \"\", explicit_paddings = [], ksize = [1, 1, 3, 3], padding = \"VALID\", strides = [1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# Uncomment this line for float16 quantization.\n",
    "# converter.target_spec.supported_types = [tf.float16]\n",
    "# converter.target_spec.supported_types = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "\n",
    "\n",
    "# Uncomment For Integer Quantization\n",
    "def representative_data_gen():\n",
    "    for file in os.listdir(dataset_path)[:10]:\n",
    "        file_path = dataset_path+file\n",
    "        image = loadImage(file_path)\n",
    "        image = cv2.resize(image, dsize=(600, 800), interpolation=cv2.INTER_LINEAR)\n",
    "        img_resized, target_ratio, size_heatmap = resize_aspect_ratio(image, 1280, interpolation=cv2.INTER_LINEAR, mag_ratio=1.5)\n",
    "        ratio_h = ratio_w = 1 / target_ratio\n",
    "\n",
    "        # preprocessing\n",
    "        x = normalizeMeanVariance(img_resized)\n",
    "        x = torch.from_numpy(x).permute(2, 0, 1)    # [h, w, c] to [c, h, w]\n",
    "        x = Variable(x.unsqueeze(0))                # [c, h, w] to [b, c, h, w]\n",
    "        x = x.cpu().detach().numpy()\n",
    "        yield [x]\n",
    "\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "tf_lite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3b0Sn3NUm6hh"
   },
   "outputs": [],
   "source": [
    "open('craft_800_int.tflite', 'wb').write(tf_lite_model)\n",
    "\n",
    "print(\"Converted to tensorflow lite succesfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tflite_model(input_data):\n",
    "    print(input_data.shape)\n",
    "    # Load the TFLite model and allocate tensors.\n",
    "    interpreter = tf.lite.Interpreter(model_path=\"craft_800_int.tflite\")\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Get input and output tensors.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    " \n",
    "    # Test the model on random input data.\n",
    "    input_shape = input_details[0]['shape']\n",
    "    # input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # The function `get_tensor()` returns a copy of the tensor data.\n",
    "    # Use `tensor()` in order to get a pointer to the tensor.\n",
    "    y = interpreter.get_tensor(output_details[0]['index'])\n",
    "    feature = interpreter.get_tensor(output_details[1]['index'])\n",
    "\n",
    "    return y, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/content/000.jpg'\n",
    "start_time = time.time()\n",
    "image = loadImage(image_path)\n",
    "image = cv2.resize(image, dsize=(800, 1280), interpolation=cv2.INTER_LINEAR)\n",
    "img_resized, target_ratio, size_heatmap = resize_aspect_ratio(image, canvas_size, interpolation=cv2.INTER_LINEAR, mag_ratio=mag_ratio)\n",
    "ratio_h = ratio_w = 1 / target_ratio\n",
    "\n",
    "# preprocessing\n",
    "x = normalizeMeanVariance(img_resized)\n",
    "x = torch.from_numpy(x).permute(2, 0, 1)    # [h, w, c] to [c, h, w]\n",
    "x = Variable(x.unsqueeze(0))                # [c, h, w] to [b, c, h, w]\n",
    "# forward pass\n",
    "\n",
    "x = x.cpu().detach().numpy()\n",
    "y, feature = run_tflite_model(x)\n",
    "\n",
    "y = torch.from_numpy(y)\n",
    "feature = torch.from_numpy(feature)\n",
    "# make score and link map\n",
    "score_text = y[0,:,:,0].cpu().data.numpy()\n",
    "score_link = y[0,:,:,1].cpu().data.numpy()\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "boxes, polys = getDetBoxes(score_text, score_link, text_threshold, link_threshold, low_text, poly)\n",
    "\n",
    "# coordinate adjustment\n",
    "boxes = adjustResultCoordinates(boxes, ratio_w, ratio_h)\n",
    "polys = adjustResultCoordinates(polys, ratio_w, ratio_h)\n",
    "for k in range(len(polys)):\n",
    "    if polys[k] is None: polys[k] = boxes[k]\n",
    "\n",
    "# render results (optional)\n",
    "render_img = score_text.copy()\n",
    "render_img = np.hstack((render_img, score_link))\n",
    "ret_score_text = cvt2HeatmapImg(render_img)\n",
    "\n",
    "\n",
    "saveResult(image_path, image[:,:,::-1], polys, dirname=result_folder)\n",
    "filename, file_ext = os.path.splitext(os.path.basename(image_path))\n",
    "print(\"Total time taken to run CRAFT tflite model......\", time.time()-start_time)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "savedmodel_to_tflite.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
