{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tulasiram58827/craft_tflite/blob/main/colabs/pytorch_to_onnx.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook converts CRAFT Pytorch Pretrained [model](https://drive.google.com/uc?export=download&id=1Jk4eGD7crsqCCg9C9VjCLkMN3ze8kutZ) to ONNX Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SetUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H0jOHyjhhMNB",
    "outputId": "f6177e4e-db5c-4108-8c28-ed8e5339c074"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Authors\n",
    " * Tulasi Ram\n",
    "\"\"\"\n",
    "\n",
    "!pip install onnx\n",
    "!pip install onnxruntime\n",
    "!pip install pip install git+https://github.com/onnx/onnx-tensorflow.git\n",
    "\n",
    "\n",
    "import gdown\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import models\n",
    "from torchvision.models.vgg import model_urls\n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from onnx_tf.backend import prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t3Q_RNE9hHoL"
   },
   "outputs": [],
   "source": [
    "def copyStateDict(state_dict):\n",
    "    if list(state_dict.keys())[0].startswith(\"module\"):\n",
    "        start_idx = 1\n",
    "    else:\n",
    "        start_idx = 0\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = \".\".join(k.split(\".\")[start_idx:])\n",
    "        new_state_dict[name] = v\n",
    "    return new_state_dict\n",
    "\n",
    "def init_weights(modules):\n",
    "    for m in modules:\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.xavier_uniform_(m.weight.data)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.data.fill_(1)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0, 0.01)\n",
    "            m.bias.data.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fV9nYbloikdE"
   },
   "outputs": [],
   "source": [
    "class vgg16_bn(torch.nn.Module):\n",
    "    def __init__(self, pretrained=True, freeze=True):\n",
    "        super(vgg16_bn, self).__init__()\n",
    "        model_urls['vgg16_bn'] = model_urls['vgg16_bn'].replace('https://', 'http://')\n",
    "        vgg_pretrained_features = models.vgg16_bn(pretrained=pretrained).features\n",
    "        self.slice1 = torch.nn.Sequential()\n",
    "        self.slice2 = torch.nn.Sequential()\n",
    "        self.slice3 = torch.nn.Sequential()\n",
    "        self.slice4 = torch.nn.Sequential()\n",
    "        self.slice5 = torch.nn.Sequential()\n",
    "        for x in range(12):         # conv2_2\n",
    "            self.slice1.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(12, 19):         # conv3_3\n",
    "            self.slice2.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(19, 29):         # conv4_3\n",
    "            self.slice3.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(29, 39):         # conv5_3\n",
    "            self.slice4.add_module(str(x), vgg_pretrained_features[x])\n",
    "\n",
    "        # fc6, fc7 without atrous conv\n",
    "        self.slice5 = torch.nn.Sequential(\n",
    "                nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(512, 1024, kernel_size=3, padding=6, dilation=6),\n",
    "                nn.Conv2d(1024, 1024, kernel_size=1)\n",
    "        )\n",
    "\n",
    "        if not pretrained:\n",
    "            init_weights(self.slice1.modules())\n",
    "            init_weights(self.slice2.modules())\n",
    "            init_weights(self.slice3.modules())\n",
    "            init_weights(self.slice4.modules())\n",
    "\n",
    "        init_weights(self.slice5.modules())        # no pretrained model for fc6 and fc7\n",
    "\n",
    "        if freeze:\n",
    "            for param in self.slice1.parameters():      # only first conv\n",
    "                param.requires_grad= False\n",
    "\n",
    "    def forward(self, X):\n",
    "        h = self.slice1(X)\n",
    "        h_relu2_2 = h\n",
    "        h = self.slice2(h)\n",
    "        h_relu3_2 = h\n",
    "        h = self.slice3(h)\n",
    "        h_relu4_3 = h\n",
    "        h = self.slice4(h)\n",
    "        h_relu5_3 = h\n",
    "        h = self.slice5(h)\n",
    "        h_fc7 = h\n",
    "        vgg_outputs = namedtuple(\"VggOutputs\", ['fc7', 'relu5_3', 'relu4_3', 'relu3_2', 'relu2_2'])\n",
    "        out = vgg_outputs(h_fc7, h_relu5_3, h_relu4_3, h_relu3_2, h_relu2_2)\n",
    "        return out\n",
    "\n",
    "class double_conv(nn.Module):\n",
    "    def __init__(self, in_ch, mid_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch + mid_ch, mid_ch, kernel_size=1),\n",
    "            nn.BatchNorm2d(mid_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Craft Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ybz4MHHIio-Q"
   },
   "outputs": [],
   "source": [
    "class CRAFT(nn.Module):\n",
    "    def __init__(self, pretrained=False, freeze=False):\n",
    "        super(CRAFT, self).__init__()\n",
    "\n",
    "        \"\"\" Base network \"\"\"\n",
    "        self.basenet = vgg16_bn(pretrained, freeze)\n",
    "\n",
    "        \"\"\" U network \"\"\"\n",
    "        self.upconv1 = double_conv(1024, 512, 256)\n",
    "        self.upconv2 = double_conv(512, 256, 128)\n",
    "        self.upconv3 = double_conv(256, 128, 64)\n",
    "        self.upconv4 = double_conv(128, 64, 32)\n",
    "\n",
    "        num_class = 2\n",
    "        self.conv_cls = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 16, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 16, kernel_size=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, num_class, kernel_size=1),\n",
    "        )\n",
    "\n",
    "        init_weights(self.upconv1.modules())\n",
    "        init_weights(self.upconv2.modules())\n",
    "        init_weights(self.upconv3.modules())\n",
    "        init_weights(self.upconv4.modules())\n",
    "        init_weights(self.conv_cls.modules())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\" Base network \"\"\"\n",
    "        sources = self.basenet(x)\n",
    "\n",
    "        \"\"\" U network \"\"\"\n",
    "        y = torch.cat([sources[0], sources[1]], dim=1)\n",
    "        y = self.upconv1(y)\n",
    "\n",
    "        y = F.interpolate(y, size=sources[2].size()[2:], mode='bilinear', align_corners=False)\n",
    "        y = torch.cat([y, sources[2]], dim=1)\n",
    "        y = self.upconv2(y)\n",
    "\n",
    "        y = F.interpolate(y, size=sources[3].size()[2:], mode='bilinear', align_corners=False)\n",
    "        y = torch.cat([y, sources[3]], dim=1)\n",
    "        y = self.upconv3(y)\n",
    "\n",
    "        y = F.interpolate(y, size=sources[4].size()[2:], mode='bilinear', align_corners=False)\n",
    "        y = torch.cat([y, sources[4]], dim=1)\n",
    "        feature = self.upconv4(y)\n",
    "\n",
    "        y = self.conv_cls(feature)\n",
    "\n",
    "        return y.permute(0,2,3,1), feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OEhpCyujWCK"
   },
   "outputs": [],
   "source": [
    "# Link to the pretrained model.\n",
    "# https://drive.google.com/uc?export=download&id=1Jk4eGD7crsqCCg9C9VjCLkMN3ze8kutZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O9ndN1rpirzF",
    "outputId": "167ac3e9-5b38-441c-8705-41dc19d1aedb"
   },
   "outputs": [],
   "source": [
    "net = CRAFT()\n",
    "net.load_state_dict(copyStateDict(torch.load('craft_mlt_25k.pth', map_location='cpu')))\n",
    "#net.load_state_dict(copyStateDict(torch.load('.EasyOCR/model/craft_mlt_25k.pth', map_location='cuda')))\n",
    "#net = torch.nn.DataParallel(net).to('cuda')\n",
    "#cudnn.benchmark = False\n",
    "print(\"Model loaded\")\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JBUdAMeIiuW-",
    "outputId": "19a1677e-377b-4812-b1c2-56ed17386763"
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "# Input to the model\n",
    "x = torch.randn(batch_size, 3, 224, 224, requires_grad=True)\n",
    "onnx_runtime_input = x.detach().numpy()\n",
    "t1 = datetime.now()\n",
    "torch_out = net(x)\n",
    "t2 = datetime.now()\n",
    "print(\"Time taken for Pytoch model\", str(t2-t1))\n",
    "store_out = torch_out[0].detach().numpy()\n",
    "print(\"Output size\", torch_out[0].size())\n",
    "print(\"Model ran sucesfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vpJeKd8plDHj",
    "outputId": "5cc5d779-5a1e-4ac2-b86c-cfb9a671c514"
   },
   "outputs": [],
   "source": [
    "# Export the model\n",
    "torch.onnx.export(net,               # model being run\n",
    "                  x,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"craft.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size',\n",
    "                                           2 : 'width',\n",
    "                                           3 : 'height'},    # variable lenght axes\n",
    "                                'output' : {0 : 'batch_size',\n",
    "                                            1 : 'width',\n",
    "                                            2: 'height'}})\n",
    "print(\"Model converted succesfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RF_HysIMlGCG",
    "outputId": "93a846cd-72d8-4eaa-e952-a14ae32421ae"
   },
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(\"craft.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"Model checked succesfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference with ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HfuqPQ6UlJTJ",
    "outputId": "2e00a119-9558-4348-a81a-1a246bf4f65b"
   },
   "outputs": [],
   "source": [
    "ort_session = onnxruntime.InferenceSession(\"craft.onnx\")\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    print(tensor)\n",
    "    return tensor.detach().cpu().numpy()\n",
    "\n",
    "# # compute ONNX Runtime output prediction\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: onnx_runtime_input}\n",
    "t1 = datetime.now()\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "t2 = datetime.now()\n",
    "print(\"Time taken for Onnx model\", str(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNuTGsR_lPqH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pytorch_to_onnx.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
